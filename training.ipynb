{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13c82530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"labelled_data_period1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ca5d2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>percentile_last_30</th>\n",
       "      <th>Open_t1</th>\n",
       "      <th>...</th>\n",
       "      <th>T10YIE</th>\n",
       "      <th>DFF</th>\n",
       "      <th>VIXCLS</th>\n",
       "      <th>Open_SP500</th>\n",
       "      <th>High_SP500</th>\n",
       "      <th>Low_SP500</th>\n",
       "      <th>Close_SP500</th>\n",
       "      <th>Adj Close_SP500</th>\n",
       "      <th>Volume_SP500</th>\n",
       "      <th>USRECD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>2005-02-15</td>\n",
       "      <td>44.150002</td>\n",
       "      <td>44.529999</td>\n",
       "      <td>43.790001</td>\n",
       "      <td>43.950001</td>\n",
       "      <td>43.950001</td>\n",
       "      <td>165399</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>44.650002</td>\n",
       "      <td>...</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.53</td>\n",
       "      <td>11.27</td>\n",
       "      <td>1206.140015</td>\n",
       "      <td>1212.439941</td>\n",
       "      <td>1205.520020</td>\n",
       "      <td>1210.119995</td>\n",
       "      <td>1210.119995</td>\n",
       "      <td>1527080000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>2005-02-16</td>\n",
       "      <td>43.990002</td>\n",
       "      <td>44.660000</td>\n",
       "      <td>43.910000</td>\n",
       "      <td>44.450001</td>\n",
       "      <td>44.450001</td>\n",
       "      <td>232170</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>44.150002</td>\n",
       "      <td>...</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.48</td>\n",
       "      <td>11.10</td>\n",
       "      <td>1210.119995</td>\n",
       "      <td>1212.439941</td>\n",
       "      <td>1205.060059</td>\n",
       "      <td>1210.339966</td>\n",
       "      <td>1210.339966</td>\n",
       "      <td>1490100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2005-02-17</td>\n",
       "      <td>44.320000</td>\n",
       "      <td>44.520000</td>\n",
       "      <td>43.509998</td>\n",
       "      <td>43.520000</td>\n",
       "      <td>43.520000</td>\n",
       "      <td>225170</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>43.990002</td>\n",
       "      <td>...</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.50</td>\n",
       "      <td>11.77</td>\n",
       "      <td>1210.339966</td>\n",
       "      <td>1211.329956</td>\n",
       "      <td>1200.739990</td>\n",
       "      <td>1200.750000</td>\n",
       "      <td>1200.750000</td>\n",
       "      <td>1580120000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>2005-02-18</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>43.730000</td>\n",
       "      <td>42.959999</td>\n",
       "      <td>43.009998</td>\n",
       "      <td>43.009998</td>\n",
       "      <td>259199</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>44.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>11.18</td>\n",
       "      <td>1200.750000</td>\n",
       "      <td>1202.920044</td>\n",
       "      <td>1197.349976</td>\n",
       "      <td>1201.589966</td>\n",
       "      <td>1201.589966</td>\n",
       "      <td>1551200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2005-02-22</td>\n",
       "      <td>43.009998</td>\n",
       "      <td>43.400002</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>42.610001</td>\n",
       "      <td>42.610001</td>\n",
       "      <td>280175</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>...</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.57</td>\n",
       "      <td>13.14</td>\n",
       "      <td>1201.589966</td>\n",
       "      <td>1202.479980</td>\n",
       "      <td>1184.160034</td>\n",
       "      <td>1184.160034</td>\n",
       "      <td>1184.160034</td>\n",
       "      <td>1744940000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date       Open       High        Low      Close  \\\n",
       "0          30  2005-02-15  44.150002  44.529999  43.790001  43.950001   \n",
       "1          31  2005-02-16  43.990002  44.660000  43.910000  44.450001   \n",
       "2          32  2005-02-17  44.320000  44.520000  43.509998  43.520000   \n",
       "3          33  2005-02-18  43.380001  43.730000  42.959999  43.009998   \n",
       "4          34  2005-02-22  43.009998  43.400002  42.250000  42.610001   \n",
       "\n",
       "   Adj Close  Volume  percentile_last_30    Open_t1  ...  T10YIE   DFF  \\\n",
       "0  43.950001  165399           56.666667  44.650002  ...    2.49  2.53   \n",
       "1  44.450001  232170           76.666667  44.150002  ...    2.51  2.48   \n",
       "2  43.520000  225170           50.000000  43.990002  ...    2.54  2.50   \n",
       "3  43.009998  259199           43.333333  44.320000  ...    2.60  2.51   \n",
       "4  42.610001  280175           40.000000  43.380001  ...    2.62  2.57   \n",
       "\n",
       "   VIXCLS   Open_SP500   High_SP500    Low_SP500  Close_SP500  \\\n",
       "0   11.27  1206.140015  1212.439941  1205.520020  1210.119995   \n",
       "1   11.10  1210.119995  1212.439941  1205.060059  1210.339966   \n",
       "2   11.77  1210.339966  1211.329956  1200.739990  1200.750000   \n",
       "3   11.18  1200.750000  1202.920044  1197.349976  1201.589966   \n",
       "4   13.14  1201.589966  1202.479980  1184.160034  1184.160034   \n",
       "\n",
       "   Adj Close_SP500  Volume_SP500  USRECD  \n",
       "0      1210.119995    1527080000       0  \n",
       "1      1210.339966    1490100000       0  \n",
       "2      1200.750000    1580120000       0  \n",
       "3      1201.589966    1551200000       0  \n",
       "4      1184.160034    1744940000       0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2abcd7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57126ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>percentile_last_30</th>\n",
       "      <th>Open_t1</th>\n",
       "      <th>High_t1</th>\n",
       "      <th>...</th>\n",
       "      <th>T10YIE</th>\n",
       "      <th>DFF</th>\n",
       "      <th>VIXCLS</th>\n",
       "      <th>Open_SP500</th>\n",
       "      <th>High_SP500</th>\n",
       "      <th>Low_SP500</th>\n",
       "      <th>Close_SP500</th>\n",
       "      <th>Adj Close_SP500</th>\n",
       "      <th>Volume_SP500</th>\n",
       "      <th>USRECD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-02-15</td>\n",
       "      <td>44.150002</td>\n",
       "      <td>44.529999</td>\n",
       "      <td>43.790001</td>\n",
       "      <td>43.950001</td>\n",
       "      <td>43.950001</td>\n",
       "      <td>165399</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>44.650002</td>\n",
       "      <td>44.930000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.53</td>\n",
       "      <td>11.27</td>\n",
       "      <td>1206.140015</td>\n",
       "      <td>1212.439941</td>\n",
       "      <td>1205.520020</td>\n",
       "      <td>1210.119995</td>\n",
       "      <td>1210.119995</td>\n",
       "      <td>1527080000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-02-16</td>\n",
       "      <td>43.990002</td>\n",
       "      <td>44.660000</td>\n",
       "      <td>43.910000</td>\n",
       "      <td>44.450001</td>\n",
       "      <td>44.450001</td>\n",
       "      <td>232170</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>44.150002</td>\n",
       "      <td>44.529999</td>\n",
       "      <td>...</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.48</td>\n",
       "      <td>11.10</td>\n",
       "      <td>1210.119995</td>\n",
       "      <td>1212.439941</td>\n",
       "      <td>1205.060059</td>\n",
       "      <td>1210.339966</td>\n",
       "      <td>1210.339966</td>\n",
       "      <td>1490100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-02-17</td>\n",
       "      <td>44.320000</td>\n",
       "      <td>44.520000</td>\n",
       "      <td>43.509998</td>\n",
       "      <td>43.520000</td>\n",
       "      <td>43.520000</td>\n",
       "      <td>225170</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>43.990002</td>\n",
       "      <td>44.660000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.50</td>\n",
       "      <td>11.77</td>\n",
       "      <td>1210.339966</td>\n",
       "      <td>1211.329956</td>\n",
       "      <td>1200.739990</td>\n",
       "      <td>1200.750000</td>\n",
       "      <td>1200.750000</td>\n",
       "      <td>1580120000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-02-18</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>43.730000</td>\n",
       "      <td>42.959999</td>\n",
       "      <td>43.009998</td>\n",
       "      <td>43.009998</td>\n",
       "      <td>259199</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>44.320000</td>\n",
       "      <td>44.520000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>11.18</td>\n",
       "      <td>1200.750000</td>\n",
       "      <td>1202.920044</td>\n",
       "      <td>1197.349976</td>\n",
       "      <td>1201.589966</td>\n",
       "      <td>1201.589966</td>\n",
       "      <td>1551200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-02-22</td>\n",
       "      <td>43.009998</td>\n",
       "      <td>43.400002</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>42.610001</td>\n",
       "      <td>42.610001</td>\n",
       "      <td>280175</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>43.730000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.57</td>\n",
       "      <td>13.14</td>\n",
       "      <td>1201.589966</td>\n",
       "      <td>1202.479980</td>\n",
       "      <td>1184.160034</td>\n",
       "      <td>1184.160034</td>\n",
       "      <td>1184.160034</td>\n",
       "      <td>1744940000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  Volume  \\\n",
       "0  2005-02-15  44.150002  44.529999  43.790001  43.950001  43.950001  165399   \n",
       "1  2005-02-16  43.990002  44.660000  43.910000  44.450001  44.450001  232170   \n",
       "2  2005-02-17  44.320000  44.520000  43.509998  43.520000  43.520000  225170   \n",
       "3  2005-02-18  43.380001  43.730000  42.959999  43.009998  43.009998  259199   \n",
       "4  2005-02-22  43.009998  43.400002  42.250000  42.610001  42.610001  280175   \n",
       "\n",
       "   percentile_last_30    Open_t1    High_t1  ...  T10YIE   DFF  VIXCLS  \\\n",
       "0           56.666667  44.650002  44.930000  ...    2.49  2.53   11.27   \n",
       "1           76.666667  44.150002  44.529999  ...    2.51  2.48   11.10   \n",
       "2           50.000000  43.990002  44.660000  ...    2.54  2.50   11.77   \n",
       "3           43.333333  44.320000  44.520000  ...    2.60  2.51   11.18   \n",
       "4           40.000000  43.380001  43.730000  ...    2.62  2.57   13.14   \n",
       "\n",
       "    Open_SP500   High_SP500    Low_SP500  Close_SP500  Adj Close_SP500  \\\n",
       "0  1206.140015  1212.439941  1205.520020  1210.119995      1210.119995   \n",
       "1  1210.119995  1212.439941  1205.060059  1210.339966      1210.339966   \n",
       "2  1210.339966  1211.329956  1200.739990  1200.750000      1200.750000   \n",
       "3  1200.750000  1202.920044  1197.349976  1201.589966      1201.589966   \n",
       "4  1201.589966  1202.479980  1184.160034  1184.160034      1184.160034   \n",
       "\n",
       "   Volume_SP500  USRECD  \n",
       "0    1527080000       0  \n",
       "1    1490100000       0  \n",
       "2    1580120000       0  \n",
       "3    1551200000       0  \n",
       "4    1744940000       0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c98719b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the position of cols\n",
    "#cols = [cols[7]] + cols[0:7] + cols[8:]\n",
    "#df = df[cols]\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "084ec105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
       "       'percentile_last_30', 'Open_t1', 'High_t1', 'Low_t1', 'Close_t1',\n",
       "       'Adj Close_t1', 'Volume_t1', 'T10Y2Y', 'T10YIE', 'DFF', 'VIXCLS',\n",
       "       'Open_SP500', 'High_SP500', 'Low_SP500', 'Close_SP500',\n",
       "       'Adj Close_SP500', 'Volume_SP500'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3bf23fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df.columns[1:24]\\ndf.dtypes\\ndf['T10Y2Y'] = df['T10Y2Y'].replace('.', pd.np.nan)\\ndf['T10Y2Y'] = df['T10Y2Y'].astype(float)\\ndf['T10YIE'] = df['T10YIE'].replace('.', pd.np.nan)\\ndf['T10YIE'] = df['T10YIE'].astype(float)\\ndf.columns[1:24]\\ndf.dtypes\\ndf = df.dropna()\\ndf.head()\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert datatypes of all cols to int or float\n",
    "'''df.columns[1:24]\n",
    "df.dtypes\n",
    "df['T10Y2Y'] = df['T10Y2Y'].replace('.', pd.np.nan)\n",
    "df['T10Y2Y'] = df['T10Y2Y'].astype(float)\n",
    "df['T10YIE'] = df['T10YIE'].replace('.', pd.np.nan)\n",
    "df['T10YIE'] = df['T10YIE'].astype(float)\n",
    "df.columns[1:24]\n",
    "df.dtypes\n",
    "df = df.dropna()\n",
    "df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8f3a0",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c073d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>percentile_last_30</th>\n",
       "      <th>Open_t1</th>\n",
       "      <th>High_t1</th>\n",
       "      <th>...</th>\n",
       "      <th>T10YIE</th>\n",
       "      <th>DFF</th>\n",
       "      <th>VIXCLS</th>\n",
       "      <th>Open_SP500</th>\n",
       "      <th>High_SP500</th>\n",
       "      <th>Low_SP500</th>\n",
       "      <th>Close_SP500</th>\n",
       "      <th>Adj Close_SP500</th>\n",
       "      <th>Volume_SP500</th>\n",
       "      <th>USRECD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-02-15</td>\n",
       "      <td>0.554047</td>\n",
       "      <td>0.453915</td>\n",
       "      <td>0.682126</td>\n",
       "      <td>0.591364</td>\n",
       "      <td>0.591364</td>\n",
       "      <td>0.015858</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.562640</td>\n",
       "      <td>0.459578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900735</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>0.594852</td>\n",
       "      <td>0.587146</td>\n",
       "      <td>0.606221</td>\n",
       "      <td>0.600470</td>\n",
       "      <td>0.600470</td>\n",
       "      <td>0.074748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-02-16</td>\n",
       "      <td>0.551298</td>\n",
       "      <td>0.455755</td>\n",
       "      <td>0.684668</td>\n",
       "      <td>0.600630</td>\n",
       "      <td>0.600630</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.554047</td>\n",
       "      <td>0.453915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908088</td>\n",
       "      <td>0.453358</td>\n",
       "      <td>0.017049</td>\n",
       "      <td>0.599345</td>\n",
       "      <td>0.587146</td>\n",
       "      <td>0.605703</td>\n",
       "      <td>0.600718</td>\n",
       "      <td>0.600718</td>\n",
       "      <td>0.071302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-02-17</td>\n",
       "      <td>0.556969</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.676197</td>\n",
       "      <td>0.583395</td>\n",
       "      <td>0.583395</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.551298</td>\n",
       "      <td>0.455755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>0.457090</td>\n",
       "      <td>0.026490</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.585886</td>\n",
       "      <td>0.600842</td>\n",
       "      <td>0.589926</td>\n",
       "      <td>0.589926</td>\n",
       "      <td>0.079690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-02-18</td>\n",
       "      <td>0.540815</td>\n",
       "      <td>0.442588</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.573944</td>\n",
       "      <td>0.573944</td>\n",
       "      <td>0.028371</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.556969</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.458955</td>\n",
       "      <td>0.018177</td>\n",
       "      <td>0.588766</td>\n",
       "      <td>0.576338</td>\n",
       "      <td>0.597027</td>\n",
       "      <td>0.590871</td>\n",
       "      <td>0.590871</td>\n",
       "      <td>0.076995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-02-22</td>\n",
       "      <td>0.534456</td>\n",
       "      <td>0.437916</td>\n",
       "      <td>0.649513</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>0.031169</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.540815</td>\n",
       "      <td>0.442588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948529</td>\n",
       "      <td>0.470149</td>\n",
       "      <td>0.045794</td>\n",
       "      <td>0.589714</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.582185</td>\n",
       "      <td>0.571257</td>\n",
       "      <td>0.571257</td>\n",
       "      <td>0.095049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
       "0  2005-02-15  0.554047  0.453915  0.682126  0.591364   0.591364  0.015858   \n",
       "1  2005-02-16  0.551298  0.455755  0.684668  0.600630   0.600630  0.024765   \n",
       "2  2005-02-17  0.556969  0.453773  0.676197  0.583395   0.583395  0.023831   \n",
       "3  2005-02-18  0.540815  0.442588  0.664549  0.573944   0.573944  0.028371   \n",
       "4  2005-02-22  0.534456  0.437916  0.649513  0.566531   0.566531  0.031169   \n",
       "\n",
       "   percentile_last_30   Open_t1   High_t1  ...    T10YIE       DFF    VIXCLS  \\\n",
       "0            0.566667  0.562640  0.459578  ...  0.900735  0.462687  0.019445   \n",
       "1            0.766667  0.554047  0.453915  ...  0.908088  0.453358  0.017049   \n",
       "2            0.500000  0.551298  0.455755  ...  0.919118  0.457090  0.026490   \n",
       "3            0.433333  0.556969  0.453773  ...  0.941176  0.458955  0.018177   \n",
       "4            0.400000  0.540815  0.442588  ...  0.948529  0.470149  0.045794   \n",
       "\n",
       "   Open_SP500  High_SP500  Low_SP500  Close_SP500  Adj Close_SP500  \\\n",
       "0    0.594852    0.587146   0.606221     0.600470         0.600470   \n",
       "1    0.599345    0.587146   0.605703     0.600718         0.600718   \n",
       "2    0.599594    0.585886   0.600842     0.589926         0.589926   \n",
       "3    0.588766    0.576338   0.597027     0.590871         0.590871   \n",
       "4    0.589714    0.575838   0.582185     0.571257         0.571257   \n",
       "\n",
       "   Volume_SP500  USRECD  \n",
       "0      0.074748       0  \n",
       "1      0.071302       0  \n",
       "2      0.079690       0  \n",
       "3      0.076995       0  \n",
       "4      0.095049       0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "feature_columns = df.columns[1:24]\n",
    "label = df.columns[24:25]\n",
    "#print(feature_columns)\n",
    "\n",
    "df[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c13a9",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e45edb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 training data shape = ((884, 23), (884, 1))\n",
      "Fold 1 validation data shape = ((222, 23), (222, 1))\n",
      "Fold 2 training data shape = ((885, 23), (885, 1))\n",
      "Fold 2 validation data shape = ((221, 23), (221, 1))\n",
      "Fold 3 training data shape = ((885, 23), (885, 1))\n",
      "Fold 3 validation data shape = ((221, 23), (221, 1))\n",
      "Fold 4 training data shape = ((885, 23), (885, 1))\n",
      "Fold 4 validation data shape = ((221, 23), (221, 1))\n",
      "Fold 5 training data shape = ((885, 23), (885, 1))\n",
      "Fold 5 validation data shape = ((221, 23), (221, 1))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# First extract our test data and store it in x_test, y_test\n",
    "features = df[feature_columns].to_numpy()\n",
    "labels = df[label].to_numpy()\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42) #_x is the rest of the data\n",
    "\n",
    "# set k = 5\n",
    "k = 5\n",
    "\n",
    "kfold_spliiter = KFold(n_splits=k)\n",
    "\n",
    "folds_data = [] # this is an inefficient way but still do it\n",
    "\n",
    "fold = 1\n",
    "for train_index, validation_index in kfold_spliiter.split(_x):\n",
    "    x_train , x_valid = _x[train_index,:],_x[validation_index,:]\n",
    "    y_train , y_valid = _y[train_index,:] , _y[validation_index,:]\n",
    "    print (f\"Fold {fold} training data shape = {(x_train.shape,y_train.shape)}\")\n",
    "    print (f\"Fold {fold} validation data shape = {(x_valid.shape,y_valid.shape)}\")\n",
    "    fold+=1\n",
    "    folds_data.append((x_train,y_train,x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2906064",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "352abc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's define our models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "# LR with no regularizer\n",
    "lr_vanilla = LogisticRegression(penalty='none')\n",
    "lr_L2 = LogisticRegression(penalty=\"l2\")\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(random_state=23) # some random seed for reproducibility\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "voting = VotingClassifier(estimators=[(\"1\",lr_vanilla),(\"2\",svm_linear),(\"3\",dt)])\n",
    "\n",
    "\n",
    "\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "svm_poly = SVC(kernel=\"poly\",degree=2)\n",
    "\n",
    "# Keep all the models in a dictionary\n",
    "\n",
    "all_models = {\"lr_vanilla\":lr_vanilla, \n",
    "              \"lr_L2\":lr_L2,\n",
    "              \"svm_linear\":svm_linear,\n",
    "              \"svm_poly\":svm_poly,\n",
    "             \"decision_tree\":dt,\n",
    "              \"random_forest\":rf,\n",
    "              \"grad_boost\":grad_boost,\n",
    "              \"voting\":voting}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35cc826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lr_vanilla ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuning/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yuning/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yuning/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yuning/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yuning/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy for model lr_vanilla = 0.9247281233223406\n",
      "Average validation accuracy for model lr_vanilla = 0.9204272145448616\n",
      "-----------------------------------\n",
      "Evaluating lr_L2 ...\n",
      "Average training accuracy for model lr_L2 = 0.8399644655776262\n",
      "Average validation accuracy for model lr_L2 = 0.8354286413109943\n",
      "-----------------------------------\n",
      "Evaluating svm_linear ...\n",
      "Average training accuracy for model svm_linear = 0.8788419357312677\n",
      "Average validation accuracy for model svm_linear = 0.8706942236354\n",
      "-----------------------------------\n",
      "Evaluating svm_poly ...\n",
      "Average training accuracy for model svm_poly = 0.9771702840197356\n",
      "Average validation accuracy for model svm_poly = 0.9801149565855448\n",
      "-----------------------------------\n",
      "Evaluating decision_tree ...\n",
      "Average training accuracy for model decision_tree = 1.0\n",
      "Average validation accuracy for model decision_tree = 0.9828135828135828\n",
      "-----------------------------------\n",
      "Evaluating random_forest ...\n",
      "Average training accuracy for model random_forest = 1.0\n",
      "Average validation accuracy for model random_forest = 0.9945742122212711\n",
      "-----------------------------------\n",
      "Evaluating grad_boost ...\n",
      "Average training accuracy for model grad_boost = 1.0\n",
      "Average validation accuracy for model grad_boost = 0.9936733113203701\n",
      "-----------------------------------\n",
      "Evaluating voting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuning/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yuning/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yuning/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy for model voting = 0.9638338829664852\n",
      "Average validation accuracy for model voting = 0.9520769638416697\n",
      "-----------------------------------\n",
      "Best model for the task is random_forest which offers the validation accuracy of 0.9945742122212711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuning/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yuning/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "best_validation_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "best_model = None\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name in all_models.keys():\n",
    "    \n",
    "    print (f\"Evaluating {model_name} ...\")\n",
    "    model = all_models[model_name]\n",
    "    \n",
    "    # Let's store training and validation accuracies for all folds\n",
    "    train_acc_for_all_folds = []\n",
    "    valid_acc_for_all_folds = []\n",
    "    \n",
    "    #Iterate over all folds\n",
    "    for i, fold in enumerate(folds_data):\n",
    "        x_train, y_train, x_valid, y_valid = fold\n",
    "\n",
    "        # Train the model\n",
    "        _ = model.fit(x_train,y_train.flatten())\n",
    "\n",
    "        # Evluate model on training data\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        \n",
    "        # Evaluate the model on validation data\n",
    "        y_pred_valid = model.predict(x_valid)\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        train_acc = accuracy_score(y_pred_train , y_train.flatten())\n",
    "        \n",
    "        # Store training accuracy for each folds\n",
    "        train_acc_for_all_folds.append(train_acc)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        valid_acc = accuracy_score(y_pred_valid , y_valid.flatten())\n",
    "\n",
    "        # Store validation accuracy for each folds\n",
    "        valid_acc_for_all_folds.append(valid_acc)\n",
    "    \n",
    "    #average training accuracy across k folds\n",
    "    avg_training_acc = sum(train_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average training accuracy for model {model_name} = {avg_training_acc}\")\n",
    "    \n",
    "    #average validation accuracy across k folds\n",
    "    avg_validation_acc = sum(valid_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average validation accuracy for model {model_name} = {avg_validation_acc}\")\n",
    "    \n",
    "    # Select best model based on average validation accuracy\n",
    "    if avg_validation_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = avg_validation_acc\n",
    "        best_model_name = model_name\n",
    "        best_model = model\n",
    "    print (f\"-----------------------------------\")\n",
    "\n",
    "print (f\"Best model for the task is {best_model_name} which offers the validation accuracy of {best_validation_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
